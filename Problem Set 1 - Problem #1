# libraries
library(tm)
library(ggplot2)
spam.path <- "data/spam/"
spam2.path <- "data/spam_2/"
easyham.path <- "data/easy_ham/"
easyham2.path <- "data/easy_ham_2/"
hardham.path <- "data/hard_ham/"
hardham2.path <- "data/hard_ham_2/"


# single element vector
get.msg <- function(path) {
    con <- file(path, open = "rt", encoding = "latin1")
    # typo here? rt for rb
    text <- readLines(con)
    # line break
    msg <- text[seq(which(text == "")[1] + 1,length(text),1)]
    close(con)
    return(paste(msg, collapse = "\n"))
}

# training the classifier.
get.tdm <- function(doc.vec) {
    control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE, 
        minDocFreq = 2)
    doc.corpus <- Corpus(VectorSource(doc.vec))
    doc.dtm <- TermDocumentMatrix(doc.corpus, control)
    return(doc.dtm)
}

### Copied from Conway's code?
count.word <- function(path, term) {
    msg <- get.msg(path)
    msg.corpus <- Corpus(VectorSource(msg))
    # Hard-coded TDM control
    control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE)
    msg.tdm <- TermDocumentMatrix(msg.corpus, control)
    word.freq <- rowSums(as.matrix(msg.tdm))
    term.freq <- word.freq[which(names(word.freq) == term)]
    # We use ifelse here because term.freq = NA if nothing is found
    return(ifelse(length(term.freq) > 0, term.freq, 0))
}

classify.email <- function(path, training.df, prior = 0.5, c = 1e-6) {
    # Here, we use many of the support functions to get the
    # email text data in a workable format
    msg <- get.msg(path)
    msg.tdm <- get.tdm(msg)
    msg.freq <- rowSums(as.matrix(msg.tdm))
    # Find intersections of words
    msg.match <- intersect(names(msg.freq), training.df$term)
    # Now, we just perform the naive Bayes calculation
    if(length(msg.match) < 1) {
        return(prior*c^(length(msg.freq)))
    }
    else {
        match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
        return(prior*prod(match.probs)*c^(length(msg.freq)-length(msg.match)))
    }
}


###

# vector into matrix
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs != "cmds")]
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep = "")))
spam.tdm <- get.tdm(all.spam)

spam.matrix <- as.matrix(spam.tdm)
spam.counts <- rowSums(spam.matrix)
spam.df <- data.frame(cbind(names(spam.counts), as.numeric(spam.counts)), stringsAsFactors = FALSE)
names(spam.df) <- c("term","frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.occurrence <- sapply(1:nrow(spam.matrix), function(i) { length(which(spam.matrix[i,]>0))/ncol(spam.matrix) })
spam.density <- spam.df$frequency / sum(spam.df$frequency)

spam.df <- transform(spam.df, density = spam.density, occurrence = spam.occurrence)

# applied to easyham
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs[1:length(spam.docs)], function(p) get.msg(paste(easyham.path,p,sep = "")))

easyham.tdm <- get.tdm(all.easyham)

easyham.matrix <- as.matrix(easyham.tdm)
easyham.counts <- rowSums(easyham.matrix)
easyham.df <- data.frame(cbind(names(easyham.counts), as.numeric(easyham.counts)), stringsAsFactors = FALSE)
names(easyham.df) <- c("term","frequency")
easyham.df$frequency <- as.numeric(easyham.df$frequency)
easyham.occurrence <- sapply(1:nrow(easyham.matrix), function(i) {length(which(easyham.matrix[i,]>0))/ncol(easyham.matrix)})
easyham.density <- easyham.df$frequency/sum(easyham.df$frequency)

easyham.df <- transform(easyham.df, density = easyham.density, occurrence = easyham.occurrence)

head(spam.df[with(spam.df, order(-occurrence)),])
 term frequency density     occurrence
2122  html  377 0.005665595 0.338
538   body  324 0.004869105 0.298
4313  table 1182 0.017763217 0.284
1435  email 661 0.009933576 0.262
1736  font   867 0.013029365 0.262
1942  head  254 0.003817138 0.246

# vs hard ham
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]

hardham.spamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path,p,sep = ""), 
    training.df = spam.df))
    
hardham.hamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path,p,sep = ""), 
    training.df = easyham.df))
    
hardham.res <- ifelse(hardham.spamtest>hardham.hamtest,TRUE,FALSE)
summary(hardham.res)

# html and 'table' count (Conway's code)
html.spam <- sapply(spam.docs, function(p) count.word(paste(spam.path,p,sep = ""), "html"))
table.spam <- sapply(spam.docs, function(p) count.word(paste(spam.path,p,sep = ""), "table"))
spam.init <- cbind(html.spam, table.spam, "SPAM")
html.easyham <- sapply(easyham.docs, function(p) count.word(paste(easyham.path,p,sep = ""), "html"))
table.easyham <- sapply(easyham.docs, function(p) count.word(paste(easyham.path,p,sep = ""), "table"))
easyham.init <- cbind(html.easyham, table.easyham, "EASYHAM")
init.df <- data.frame(rbind(spam.init, easyham.init), stringsAsFactors = FALSE)
names(init.df) <- c("html","table","type")
init.df$html <- as.numeric(init.df$html)
init.df$table <- as.numeric(init.df$table)
init.df$type <- as.factor(init.df$type)

init.plot1 <- ggplot(init.df, aes(x = html, y = table)) + geom_point(aes(shape = type)) + 
    scale_shape_manual(values = c("SPAM" = 1,"EASYHAM" = 3), name = "Email Type") + 
    xlab("Frequency of 'html'") + ylab("Freqeuncy of 'table'") + stat_abline(yintersept = 0, slope = 1) + 
    theme_bw()
ggsave(plot = init.plot1, filename = "../images/01_init_plot1.pdf", width = 10, height = 10)
    
init.plot2 <- ggplot(init.df, aes(x = html, y = table)) + geom_point(aes(shape = type), position = "jitter") + 
    scale_shape_manual(values = c("SPAM" = 1,"EASYHAM" = 3), name = "Email Type") + 
    xlab("Frequency of 'html'") + ylab("Freqeuncy of 'table'") + stat_abline(yintersept = 0, slope = 1) + 
    theme_bw()
ggsave(plot = init.plot2, filename = "../images/02_init_plot2.pdf", width = 10, height = 10)    

# classifiervs hardham
spam.classifier <- function(path) {
    pr.spam <- classify.email(path, spam.df)
    pr.ham <- classify.email(path, easyham.df)
    return(c(pr.spam, pr.ham, ifelse(pr.spam > pr.ham, 1, 0)))
}

# all email messages
easyham2.docs <- dir(easyham2.path)
easyham2.docs <- easyham2.docs[which(easyham2.docs != "cmds")]
hardham2.docs <- dir(hardham2.path)
hardham2.docs <- hardham2.docs[which(hardham2.docs != "cmds")]
spam2.docs <- dir(spam2.path)
spam2.docs <- spam2.docs[which(spam2.docs != "cmds")]

# classifying all
easyham2.class <- suppressWarnings(lapply(easyham2.docs, function(p) spam.classifier(paste(easyham2.path,p,sep = ""))))
hardham2.class <- suppressWarnings(lapply(hardham2.docs, function(p) spam.classifier(paste(hardham2.path,p,sep = ""))))
spam2.class <- suppressWarnings(lapply(spam2.docs, function(p) spam.classifier(paste(spam2.path,p,sep = ""))))

# Create a single, final, data frame with all of the classification data in it
easyham2.matrix <- do.call(rbind, easyham2.class)
easyham2.final <- cbind(easyham2.matrix, "EASYHAM")

hardham2.matrix <- do.call(rbind, hardham2.class)
hardham2.final <- cbind(hardham2.matrix, "HARDHAM")

spam2.matrix <- do.call(rbind, spam2.class)
spam2.final <- cbind(spam2.matrix, "SPAM")

class.matrix <- rbind(easyham2.final, hardham2.final, spam2.final)
class.df <- data.frame(class.matrix, stringsAsFactors = FALSE)
names(class.df) <- c("Pr.SPAM" ,"Pr.HAM", "Class", "Type")
class.df$Pr.SPAM <- as.numeric(class.df$Pr.SPAM)
class.df$Pr.HAM <- as.numeric(class.df$Pr.HAM)
class.df$Class <- as.logical(as.numeric(class.df$Class))
class.df$Type <- as.factor(class.df$Type)

# results (copied from conway)
class.plot <- ggplot(class.df, aes(x = Pr.HAM, Pr.SPAM)) +
    geom_point(aes(shape = Type, alpha = 0.5)) +
    stat_abline(yintercept = 0, slope = 1) +
    scale_x_log10() + scale_y_log10() + 
    scale_shape_manual(values = c("EASYHAM" = 1,"HARDHAM" = 2,"SPAM" = 3), name = "Email Type") + 
    scale_alpha(legend = FALSE) + xlab("log[Pr(HAM)]") + ylab("log[Pr(SPAM)]") + 
    theme_bw() + opts(axis.text.x = theme_blank(), axis.text.y = theme_blank())
ggsave(plot = class.plot, filename = "../images/03_final_classification.pdf", height = 10, width = 10)

get.results <- function(bool.vector) {
    results <- c(length(bool.vector[which(bool.vector == FALSE)])/length(bool.vector),
        length(bool.vector[which(bool.vector == TRUE)])/length(bool.vector))
    return(results)
}
# some output in worddoc
